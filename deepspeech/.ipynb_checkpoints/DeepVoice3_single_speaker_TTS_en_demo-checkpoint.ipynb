{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Za124iWvdMsZ"
   },
   "source": [
    "# DeepVoice3: Single-speaker text-to-speech demo\n",
    "\n",
    "In this notebook, you can try DeepVoice3-based single-speaker text-to-speech (en) using a model trained on [LJSpeech dataset](https://keithito.com/LJ-Speech-Dataset/). The notebook is supposed to be executed on [Google colab](https://colab.research.google.com) so you don't have to setup your machines locally.\n",
    "\n",
    "**Estimated time to complete**: 5 miniutes.\n",
    "\n",
    "- Code: https://github.com/r9y9/deepvoice3_pytorch\n",
    "- Audio samples: https://r9y9.github.io/deepvoice3_pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ml6wOhwqhGiI"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjindPTItq75"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kemMMs6pg9Rv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'deepvoice3_pytorch'...\n",
      "remote: Enumerating objects: 1105, done.\u001b[K\n",
      "remote: Total 1105 (delta 0), reused 0 (delta 0), pack-reused 1105\u001b[K\n",
      "Receiving objects: 100% (1105/1105), 6.92 MiB | 4.43 MiB/s, done.\n",
      "Resolving deltas: 100% (613/613), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import exists, join, expanduser\n",
    "\n",
    "# Clone\n",
    "name = \"deepvoice3_pytorch\"\n",
    "if not exists(name):\n",
    "  ! git clone https://github.com/r9y9/$name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntBxf7b6DCqT"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/athul/deepvoice3_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f121f5c3fc67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Change working directory to the project dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git checkout 7a10ac6763eda92595e257543494b6a95f64229b --quiet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/athul/deepvoice3_pytorch'"
     ]
    }
   ],
   "source": [
    "# Change working directory to the project dir \n",
    "os.chdir(join(expanduser(\"~\"), name),\"/projects/audrey/deepspeech\")\n",
    "\n",
    "!git checkout 7a10ac6763eda92595e257543494b6a95f64229b --quiet\n",
    "\n",
    "# Install dependencices\n",
    "!pip install -q -e '.[bin]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6VFmDe-ideo"
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "! pip install -q librosa nltk\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "# need this for English text processing frontend\n",
    "import nltk\n",
    "! python -m nltk.downloader cmudict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_l1Gd2SStt0E"
   },
   "source": [
    "### Download a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42Zwjr4UjNn_"
   },
   "outputs": [],
   "source": [
    "preset = \"20180505_deepvoice3_ljspeech.json\"\n",
    "checkpoint_path = \"20180505_deepvoice3_checkpoint_step000640000.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45Wrp8INj6Xu"
   },
   "outputs": [],
   "source": [
    "if not exists(preset):\n",
    "  !curl -O -L \"https://www.dropbox.com/s/0ck82unm0bo0rxd/20180505_deepvoice3_ljspeech.json\"\n",
    "if not exists(checkpoint_path):\n",
    "  !curl -O -L \"https://www.dropbox.com/s/5ucl9remrwy5oeg/20180505_deepvoice3_checkpoint_step000640000.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yJ90ESZiT_S"
   },
   "source": [
    "## Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FUyhiJg03dj6"
   },
   "source": [
    "### Setup hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E9sLuYgcnbZb"
   },
   "outputs": [],
   "source": [
    "import hparams\n",
    "import json\n",
    "\n",
    "    \n",
    "# Load parameters from preset\n",
    "with open(preset) as f:\n",
    "  hparams.hparams.parse_json(f.read())\n",
    "  \n",
    "# Inject frontend text processor\n",
    "import synthesis\n",
    "import train\n",
    "from deepvoice3_pytorch import frontend\n",
    "synthesis._frontend = getattr(frontend, \"en\")\n",
    "train._frontend =  getattr(frontend, \"en\")\n",
    "\n",
    "# alises\n",
    "fs = hparams.hparams.sample_rate\n",
    "hop_length = hparams.hparams.hop_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4NOldY83wG1"
   },
   "source": [
    "### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xRbelGLjiSfA"
   },
   "outputs": [],
   "source": [
    "def tts(model, text, p=0, speaker_id=None, fast=True, figures=True):\n",
    "  from synthesis import tts as _tts\n",
    "  waveform, alignment, spectrogram, mel = _tts(model, text, p, speaker_id, fast)\n",
    "  if figures:\n",
    "      visualize(alignment, spectrogram)\n",
    "  IPython.display.display(Audio(waveform, rate=fs))\n",
    "  \n",
    "def visualize(alignment, spectrogram):\n",
    "  label_fontsize = 16\n",
    "  figure(figsize=(16,16))\n",
    "\n",
    "  subplot(2,1,1)\n",
    "  imshow(alignment.T, aspect=\"auto\", origin=\"lower\", interpolation=None)\n",
    "  xlabel(\"Decoder timestamp\", fontsize=label_fontsize)\n",
    "  ylabel(\"Encoder timestamp\", fontsize=label_fontsize)\n",
    "  colorbar()\n",
    "\n",
    "  subplot(2,1,2)\n",
    "  librosa.display.specshow(spectrogram.T, sr=fs, \n",
    "                           hop_length=hop_length, x_axis=\"time\", y_axis=\"linear\")\n",
    "  xlabel(\"Time\", fontsize=label_fontsize)\n",
    "  ylabel(\"Hz\", fontsize=label_fontsize)\n",
    "  tight_layout()\n",
    "  colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2jmbSD430Ws"
   },
   "source": [
    "### Load the model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lr8pgqtYhvav"
   },
   "outputs": [],
   "source": [
    "from train import build_model\n",
    "from train import restore_parts, load_checkpoint\n",
    "\n",
    "model = build_model()\n",
    "model = load_checkpoint(checkpoint_path, model, None, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOJ3miW63ywA"
   },
   "source": [
    "### Generate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GR1XRy-ykbz_"
   },
   "outputs": [],
   "source": [
    "# Try your favorite senteneces:)\n",
    "texts = [\n",
    "    \"Scientists at the CERN laboratory say they have discovered a new particle.\",\n",
    "    \"There's a way to measure the acute emotional intelligence that has never gone out of style.\",\n",
    "    \"President Trump met with other leaders at the Group of 20 conference.\",\n",
    "    \"The Senate's bill to repeal and replace the Affordable Care Act is now imperiled.\",\n",
    "    \"Generative adversarial network or variational auto-encoder.\",\n",
    "    \"The buses aren't the problem, they actually provide a solution.\",\n",
    "    \"peter piper picked a peck of pickled peppers how many peppers did peter piper pick.\",\n",
    "    \"Some have accepted this as a miracle without any physical explanation.\",\n",
    "]\n",
    "\n",
    "for idx, text in enumerate(texts):\n",
    "  print(idx, text)\n",
    "  tts(model, text, figures=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nirMEf2J5Roy"
   },
   "outputs": [],
   "source": [
    "# With attention plot\n",
    "text = \"Generative adversarial network or variational auto-encoder.\"\n",
    "tts(model, text, figures=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ArQspYbs5Aoo"
   },
   "source": [
    "For details, please visit https://github.com/r9y9/deepvoice3_pytorch"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeepVoice3 single-speaker TTS en demo.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
